{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Openstreetmap-Project\" data-toc-modified-id=\"Openstreetmap-Project-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Openstreetmap Project</a></span><ul class=\"toc-item\"><li><span><a href=\"#List-of-modules-used\" data-toc-modified-id=\"List-of-modules-used-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>List of modules used</a></span></li><li><span><a href=\"#Set-the-data-file\" data-toc-modified-id=\"Set-the-data-file-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Set the data file</a></span></li></ul></li><li><span><a href=\"#Read-data-from-OSM-file-and-create-some-csv-files\" data-toc-modified-id=\"Read-data-from-OSM-file-and-create-some-csv-files-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Read data from OSM file and create some csv files</a></span></li><li><span><a href=\"#Create-the-database\" data-toc-modified-id=\"Create-the-database-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Create the database</a></span></li><li><span><a href=\"#Populate-the-database\" data-toc-modified-id=\"Populate-the-database-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Populate the database</a></span></li><li><span><a href=\"#Correct-the-data\" data-toc-modified-id=\"Correct-the-data-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Correct the data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Check-the-names-of-the-ways\" data-toc-modified-id=\"Check-the-names-of-the-ways-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Check the names of the ways</a></span><ul class=\"toc-item\"><li><span><a href=\"#Check-of-the-name-extentions\" data-toc-modified-id=\"Check-of-the-name-extentions-5.1.1\"><span class=\"toc-item-num\">5.1.1&nbsp;&nbsp;</span>Check of the name extentions</a></span></li><li><span><a href=\"#Check-the-correctness-of-the-hyphenation\" data-toc-modified-id=\"Check-the-correctness-of-the-hyphenation-5.1.2\"><span class=\"toc-item-num\">5.1.2&nbsp;&nbsp;</span>Check the correctness of the hyphenation</a></span></li><li><span><a href=\"#Check-the-correctness-of-the-name-composed-by-a-place\" data-toc-modified-id=\"Check-the-correctness-of-the-name-composed-by-a-place-5.1.3\"><span class=\"toc-item-num\">5.1.3&nbsp;&nbsp;</span>Check the correctness of the name composed by a place</a></span></li><li><span><a href=\"#Correction-of-values-in-the-database\" data-toc-modified-id=\"Correction-of-values-in-the-database-5.1.4\"><span class=\"toc-item-num\">5.1.4&nbsp;&nbsp;</span>Correction of values in the database</a></span></li></ul></li><li><span><a href=\"#Check-of-the-postcode\" data-toc-modified-id=\"Check-of-the-postcode-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Check of the postcode</a></span></li><li><span><a href=\"#Check-of-the-phone-number\" data-toc-modified-id=\"Check-of-the-phone-number-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Check of the phone number</a></span><ul class=\"toc-item\"><li><span><a href=\"#Correction-of-the-phone-numbers-in-the-database\" data-toc-modified-id=\"Correction-of-the-phone-numbers-in-the-database-5.3.1\"><span class=\"toc-item-num\">5.3.1&nbsp;&nbsp;</span>Correction of the phone numbers in the database</a></span></li></ul></li><li><span><a href=\"#Check-of-the-fax-numbers\" data-toc-modified-id=\"Check-of-the-fax-numbers-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>Check of the fax numbers</a></span><ul class=\"toc-item\"><li><span><a href=\"#Correction-of-the-bad-fax-number\" data-toc-modified-id=\"Correction-of-the-bad-fax-number-5.4.1\"><span class=\"toc-item-num\">5.4.1&nbsp;&nbsp;</span>Correction of the bad fax number</a></span></li></ul></li></ul></li><li><span><a href=\"#Analysis-of-the-data\" data-toc-modified-id=\"Analysis-of-the-data-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Analysis of the data</a></span><ul class=\"toc-item\"><li><span><a href=\"#How-many-nodes-in-the-database?\" data-toc-modified-id=\"How-many-nodes-in-the-database?-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>How many nodes in the database?</a></span></li><li><span><a href=\"#How-many-ways-in-the-database?\" data-toc-modified-id=\"How-many-ways-in-the-database?-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>How many ways in the database?</a></span></li><li><span><a href=\"#How-many-users-are-in-the-tables?\" data-toc-modified-id=\"How-many-users-are-in-the-tables?-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>How many users are in the tables?</a></span></li><li><span><a href=\"#List-of-different-type-of-elements-in-the-file\" data-toc-modified-id=\"List-of-different-type-of-elements-in-the-file-6.4\"><span class=\"toc-item-num\">6.4&nbsp;&nbsp;</span>List of different type of elements in the file</a></span></li><li><span><a href=\"#What-about-fire-protection?\" data-toc-modified-id=\"What-about-fire-protection?-6.5\"><span class=\"toc-item-num\">6.5&nbsp;&nbsp;</span>What about fire protection?</a></span></li></ul></li><li><span><a href=\"#Close-the-database\" data-toc-modified-id=\"Close-the-database-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Close the database</a></span></li><li><span><a href=\"#Possible-improvement\" data-toc-modified-id=\"Possible-improvement-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Possible improvement</a></span><ul class=\"toc-item\"><li><span><a href=\"#Use-a-dictionary\" data-toc-modified-id=\"Use-a-dictionary-8.1\"><span class=\"toc-item-num\">8.1&nbsp;&nbsp;</span>Use a dictionary</a></span></li><li><span><a href=\"#Cross-the-data-on-a-bigger-dataset\" data-toc-modified-id=\"Cross-the-data-on-a-bigger-dataset-8.2\"><span class=\"toc-item-num\">8.2&nbsp;&nbsp;</span>Cross the data on a bigger dataset</a></span></li><li><span><a href=\"#Better-visualisation\" data-toc-modified-id=\"Better-visualisation-8.3\"><span class=\"toc-item-num\">8.3&nbsp;&nbsp;</span>Better visualisation</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T17:14:58.168497Z",
     "start_time": "2018-09-26T17:14:57.832194Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import xml.etree.ElementTree\n",
    "import csv\n",
    "import re\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Openstreetmap Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this project is to parse data from a openstreetmap OSM file (XML format), populate a database and perform some analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of modules used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T17:14:58.772378Z",
     "start_time": "2018-09-26T17:14:58.767646Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: Version 3.6.6 (default, Sep 12 2018, 18:26:19) \n",
      "[GCC 8.0.1 20180414 (experimental) [trunk revision 259383]]\n",
      "sqlite3: sqlite3 is a python embedded module. Please refer to the python's version.\n",
      "xml.etree.ElementTree: xml is a python embedded module. Please refer to the python's version.\n",
      "os: os is a python embedded module. Please refer to the python's version.\n",
      "csv: Version 1.0\n",
      "re: Version 2.2.1\n",
      "pandas: Version 0.23.4\n",
      "matplotlib: Version 3.0.0\n",
      "numpy: Version 1.15.2\n"
     ]
    }
   ],
   "source": [
    "print(\"Python: Version {}\".format(sys.version))\n",
    "print(\"sqlite3: sqlite3 is a python embedded module. Please refer to the python's version.\")\n",
    "print(\"xml.etree.ElementTree: xml is a python embedded module. Please refer to the python's version.\")\n",
    "print(\"os: os is a python embedded module. Please refer to the python's version.\")\n",
    "print(\"csv: Version {}\".format(csv.__version__))\n",
    "print(\"re: Version {}\".format(re.__version__))\n",
    "print(\"pandas: Version {}\".format(pd.__version__))\n",
    "print('matplotlib: Version {}'.format(matplotlib.__version__))\n",
    "print('numpy: Version {}'.format(np.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the data file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is the area covers the city of Buxtehude and some area in south and east. This area contains some city and land parts and have probably less focus than big cities.\n",
    "\n",
    "The area is visible here:\n",
    "\n",
    "https://www.openstreetmap.org/export#map=12/53.4352/9.7596\n",
    "\n",
    "The data are exported in the OSM file: **Buxtehude.osm**\n",
    "\n",
    "To perform this studie a smaller subset was extracted:\n",
    "\n",
    "https://www.openstreetmap.org/export#map=14/53.4383/9.6234\n",
    "\n",
    "The data are exporter in the OSM file: **Apensen.osm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T17:14:59.461391Z",
     "start_time": "2018-09-26T17:14:59.458961Z"
    }
   },
   "outputs": [],
   "source": [
    "#dataFileName = 'Apensen.osm'\n",
    "dataFileName = 'Buxtehude.osm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T17:14:59.764400Z",
     "start_time": "2018-09-26T17:14:59.761264Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the source file Buxtehude.osm: 64.846Mb\n"
     ]
    }
   ],
   "source": [
    "statinfo = os.stat(dataFileName)\n",
    "print('Size of the source file {}: {:.3f}Mb'.format(dataFileName, statinfo.st_size / (1024 * 1024))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Database filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T17:15:00.323855Z",
     "start_time": "2018-09-26T17:15:00.319263Z"
    }
   },
   "outputs": [],
   "source": [
    "dbFileName = 'Openstreetmap.db'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data from OSM file and create some csv files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first part is to read the data from the OSM file and export them to some CSV files.\n",
    "\n",
    "For clarity the process is split in several functions (see below). Then main function is called 'parseOSMfile'.\n",
    "\n",
    "The OSM file is opened with the XML parser and the elements are read in sequence. The data are store in the relevant CSV file.\n",
    "\n",
    "At the end, one CSV file will be obtain per table in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T17:15:02.001102Z",
     "start_time": "2018-09-26T17:15:01.996298Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# List of all csv files\n",
    "csvFiles = {'node':'nodes.csv',\n",
    "         'way':'ways.csv',\n",
    "         'node_tags': 'nodes_tags.csv',\n",
    "         'way_tags': 'ways_tags.csv',\n",
    "         'way_node':'ways_nodes.csv'}\n",
    "\n",
    "# List of all fields for the csv files and the database\n",
    "fields = {'node': ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp'],\n",
    "           'way': ['id', 'user', 'uid', 'version', 'changeset', 'timestamp'],\n",
    "           'node_tags': ['id', 'key', 'value', 'type'],\n",
    "           'way_tags': ['id', 'key', 'value', 'type'],\n",
    "           'way_node': ['id', 'node_id', 'position']} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T17:15:02.519116Z",
     "start_time": "2018-09-26T17:15:02.511349Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Functions used to parse the OSM file and writte in the CSV files\n",
    "\n",
    "def initCSVfiles():\n",
    "    '''\n",
    "    Create empty csv files and add the header line\n",
    "    \n",
    "    parameters:\n",
    "    ------------\n",
    "    None\n",
    "    \n",
    "    returns:\n",
    "    --------\n",
    "    a dictionary containing the file descriptor and the csv writer object\n",
    "    '''\n",
    "    fileDescriptor = {}\n",
    "    for f in csvFiles:\n",
    "        #print('init {}'.format(files[f]))\n",
    "        fileId = open(csvFiles[f], 'w', encoding='utf-8')\n",
    "        csvWriter = csv.writer(fileId, delimiter=';',\n",
    "                            quotechar='\\'', quoting=csv.QUOTE_MINIMAL)\n",
    "        csvWriter.writerow(fields[f])\n",
    "        fileDescriptor[f] = {}\n",
    "        fileDescriptor[f]['fileId'] = fileId\n",
    "        fileDescriptor[f]['csvWriter'] = csvWriter\n",
    "        \n",
    "    return fileDescriptor\n",
    "\n",
    "def closeCSVfiles(fileDesc):\n",
    "    '''\n",
    "    Close all csv files opened\n",
    "    \n",
    "    parameters:\n",
    "    -----------\n",
    "    the file descriptor dictionary returned by the initCSVfiles function.\n",
    "    \n",
    "    returns:\n",
    "    --------\n",
    "    None\n",
    "    '''\n",
    "    for f in fileDesc:\n",
    "        fileDesc[f]['fileId'].close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T17:15:02.970574Z",
     "start_time": "2018-09-26T17:15:02.964962Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def writeElem(elemType, elem, fileDesc):\n",
    "    '''\n",
    "    write an element in the corresponding csv file\n",
    "    \n",
    "    parameters:\n",
    "    -----------\n",
    "    - elemType: a string of the type of element to be written.\n",
    "    - elem: dict of data to be written in the csv file\n",
    "    - fileDesc: dictionary of the file decriptor (given by the initCSVfiles function)\n",
    "    \n",
    "    returns:\n",
    "    --------\n",
    "    None\n",
    "    '''\n",
    "    record = []\n",
    "    for i in fields[elemType]:\n",
    "        record.append(elem[i])\n",
    "    \n",
    "    fileDesc[elemType]['csvWriter'].writerow(record)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T17:15:03.364203Z",
     "start_time": "2018-09-26T17:15:03.347633Z"
    },
    "code_folding": [
     0,
     34
    ]
   },
   "outputs": [],
   "source": [
    "def correctBadCaracters(string):\n",
    "    '''\n",
    "    remove problematic charracteres from a stings.\n",
    "    \n",
    "    All special character in the form '&#xxx;' will be removed and semi-colon will be replaced by a\n",
    "    space char.\n",
    "    \n",
    "    parameters:\n",
    "    -----------\n",
    "    - string: the string to be corrected\n",
    "    \n",
    "    returns:\n",
    "    --------\n",
    "    the input string without problematic characters\n",
    "    '''\n",
    "    correctedString = ''\n",
    "    start = 0\n",
    "    end = 0\n",
    "    \n",
    "    # Remove the '&#xxx' special caracters\n",
    "    pattern = r'&#?.*?;'\n",
    "    if re.search(pattern, string):\n",
    "        for m in re.finditer(pattern, string):\n",
    "            end = m.start()\n",
    "            correctedString += string[start:end]\n",
    "            start = m.end()\n",
    "    else:\n",
    "        correctedString = string\n",
    "    \n",
    "    # Remove remaning semi-colon\n",
    "    correctedString = correctedString.replace(';', ' ')\n",
    "    \n",
    "    return correctedString\n",
    "    \n",
    "def parseTag(id, attrib):\n",
    "    '''\n",
    "    Parse the tag k and return the value, the key and the type\n",
    "    \n",
    "    parameters:\n",
    "    -----------\n",
    "    - id: id of the node or the way\n",
    "    - attrib: XML object\n",
    "    \n",
    "    returns:\n",
    "    --------\n",
    "    a dictionary with the Id of the parent, the key, value and type\n",
    "    '''\n",
    "    \n",
    "    if 'k' in attrib:\n",
    "        pattern = re.compile('^([a-z_]+):(.*)$')\n",
    "        match = pattern.match(attrib['k'])\n",
    "    \n",
    "        if match:\n",
    "            type_ = match.group(1)\n",
    "            key = match.group(2)\n",
    "        else:\n",
    "            type_ = attrib['k']\n",
    "            key = ''\n",
    "    else:\n",
    "        key = None\n",
    "        type_ = None\n",
    "    \n",
    "    # Correct the value string which can contain problematic characters\n",
    "    value = correctBadCaracters(attrib['v'])\n",
    "    return {'id': id, 'key':key, 'value':value, 'type':type_} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T17:15:03.793080Z",
     "start_time": "2018-09-26T17:15:03.780760Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def parseElement(element, fileDesc):\n",
    "    '''\n",
    "    parse an element and write the data in the different csv files\n",
    "    \n",
    "    parameters:\n",
    "    -----------\n",
    "    - element: XML object to be parsed\n",
    "    - fileDesc: dictionary of the file decriptor (given by the initCSVfiles function)\n",
    "\n",
    "    returns:\n",
    "    --------\n",
    "    None\n",
    "    '''\n",
    "    targetElement = ['node', 'way']\n",
    "    \n",
    "    if element.tag in targetElement:\n",
    "        #print('Parsing: {}'.format(element.tag))\n",
    "        selectedAttribs = fields[element.tag]\n",
    "\n",
    "        # Parse the main elements Node and Way\n",
    "        attribs = element.attrib\n",
    "        elem = {}\n",
    "        for i in selectedAttribs:\n",
    "            elem[i] = attribs[i]  \n",
    "        writeElem(element.tag, elem, fileDesc)\n",
    "        \n",
    "        # Parse the subelements Tag and Nd\n",
    "        position = 0\n",
    "        for e in element:\n",
    "            tag = {}\n",
    "            node = {}\n",
    "            if e.tag == 'nd':\n",
    "                node = {'id': elem['id'], 'node_id': e.attrib['ref'], 'position': position}\n",
    "                position += 1\n",
    "                writeElem('way_node', node, fileDesc)\n",
    "            elif e.tag == 'tag':\n",
    "                tag = parseTag(elem['id'], e.attrib)\n",
    "                writeElem(element.tag + '_tags', tag, fileDesc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T17:15:04.157060Z",
     "start_time": "2018-09-26T17:15:04.151153Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def parseOSMfile(fileName):\n",
    "    '''\n",
    "    main function to extract the data from an OSM file to CSV files\n",
    "    \n",
    "    parameters:\n",
    "    -----------\n",
    "    fileName: string of the path of the OSM file\n",
    "    \n",
    "    returns:\n",
    "    --------\n",
    "    None\n",
    "    '''\n",
    "    fileDesc = initCSVfiles()\n",
    "    e = xml.etree.ElementTree.parse(fileName).getroot()\n",
    "    for element in e:\n",
    "        parseElement(element, fileDesc)\n",
    "    closeCSVfiles(fileDesc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CSV files can be generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T17:15:11.352427Z",
     "start_time": "2018-09-26T17:15:04.989457Z"
    }
   },
   "outputs": [],
   "source": [
    "parseOSMfile(dataFileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of all CSV files in the current directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T17:15:11.380380Z",
     "start_time": "2018-09-26T17:15:11.376038Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of csv files.\n",
      "File nodes_tags.csv (1502.7kb)\n",
      "File ways_nodes.csv (8054.3kb)\n",
      "File nodes.csv (20556.0kb)\n",
      "File ways.csv (2965.4kb)\n",
      "File ways_tags.csv (4491.3kb)\n"
     ]
    }
   ],
   "source": [
    "fileList = os.listdir()\n",
    "\n",
    "print('List of csv files.')\n",
    "pattern = re.compile('.*\\.csv$')\n",
    "for f in fileList:\n",
    "    if pattern.match(f):\n",
    "        statinfo = os.stat(f)\n",
    "        print('File {} ({:.1f}kb)'.format(f, statinfo.st_size / 1024))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those files can be used to populate the database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the CSV, it is now easy to populate the database. The database will be created with the schema contains in the file 'data_wrangling_schema.sql'\n",
    "\n",
    "The database is a SQLite one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T17:15:11.714436Z",
     "start_time": "2018-09-26T17:15:11.400446Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database file Openstreetmap.db already exists. This file will be use.\n"
     ]
    }
   ],
   "source": [
    "# Creation of the database\n",
    "\n",
    "# To avoid errors, if the database file does not exist, it is created else just the connexion will\n",
    "# be established.\n",
    "if not os.path.isfile(dbFileName):\n",
    "    conn = sqlite3.connect(dbFileName)\n",
    "    c = conn.cursor()\n",
    "    with open('data_wrangling_schema.sql') as f:\n",
    "        print('Creating database...')\n",
    "        text = f.read()\n",
    "        c.executescript(text)\n",
    "        conn.commit()\n",
    "        print('Execute SQL statement: \\n{}'.format(text))\n",
    "else:\n",
    "    print('Database file {} already exists. This file will be use.'.format(dbFileName))\n",
    "    conn = sqlite3.connect(dbFileName)\n",
    "    c = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Populate the database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The database file exists, it can be populated with the CSV files previously generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T17:15:12.074027Z",
     "start_time": "2018-09-26T17:15:11.735770Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Function to populate the dabase\n",
    "\n",
    "def populateDatabase(dbConn):\n",
    "    '''\n",
    "    populate the database with the CSV files.\n",
    "    \n",
    "    The name of the files and the table are extracted from the global table 'csvFiles'\n",
    "    \n",
    "    parameters:\n",
    "    -----------\n",
    "    - dbConn: connexion variable to the database\n",
    "    \n",
    "    returns:\n",
    "    --------\n",
    "    None\n",
    "    '''\n",
    "    for f in csvFiles:\n",
    "        print('Reading file {} for table {}'.format(csvFiles[f], csvFiles[f].split('.')[0]))\n",
    "        df = pd.read_csv(csvFiles[f], sep=';', dtype={\"id\": np.int32})\n",
    "        df.to_sql(csvFiles[f].split('.')[0], dbConn, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T17:15:24.999257Z",
     "start_time": "2018-09-26T17:15:12.097870Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file nodes.csv for table nodes\n",
      "Reading file ways.csv for table ways\n",
      "Reading file nodes_tags.csv for table nodes_tags\n",
      "Reading file ways_tags.csv for table ways_tags\n",
      "Reading file ways_nodes.csv for table ways_nodes\n"
     ]
    }
   ],
   "source": [
    "populateDatabase(conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the database is populated and can be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T16:58:15.336288Z",
     "start_time": "2018-09-26T16:58:15.331473Z"
    }
   },
   "source": [
    "# Correct the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the names of the ways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quality check of the naming can be done.\n",
    "For clarity, only the 10 first names are displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T10:12:06.324554Z",
     "start_time": "2018-09-26T10:12:06.294450Z"
    }
   },
   "outputs": [],
   "source": [
    "sqlQuery = 'SELECT DISTINCT value FROM ways_tags WHERE type == \\'addr\\' AND key=\\'street\\''\n",
    "names = pd.read_sql(sqlQuery, conn)\n",
    "names[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Germany the  naming convention of the streets is quite tricky. Some streets have only one word for some others Straße or Weg are separated and some other contains some hyphens. The rule is as the following:\n",
    "- The standard is to name the ways or place with one word. (Like 'Torfweg' or 'Falkenstraße')\n",
    "- If the name refers to a person and this name is only one word, the name will be written in one word (e.g. Goethestraße)\n",
    "- If the name refers to a person and this name is composed by several words, the name will be written in several words but separate by an hypen (e.g. 'Catharina-Gerkens-Weg')\n",
    "- If the name refer to a place, it will be written in several words (e.g. 'Buxtehuder Straße')\n",
    "- If the name refer to a quality (straight, blue...), it will be written in several words (e.g. 'Blauer Weg', 'Alter Platz')\n",
    "\n",
    "In Germany, the names of the streets are often written as \"str\" instead of 'Straße' (e.g. 'Landstr.')\n",
    "\n",
    "To verify all this rules a dictionary will be needed. This is out of scope of this project but can be taken for improvements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can be done is:\n",
    "- Check the extention of the street name ('Straße' and not 'Str.') (Can be done automaticaly)\n",
    "- Correctness of the hyphenation (should be done manually)\n",
    "- Check of name if refers to a place (it will end by 'er'). (should be done partily manually)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check of the name extentions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The name of the streets must be ' Straße' or '\\*straße' and not ' Str. or '\\*str.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T10:12:06.336711Z",
     "start_time": "2018-09-26T10:12:06.326023Z"
    }
   },
   "outputs": [],
   "source": [
    "names[names.value.str.match('.* ?[sS]tr\\.?$')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One error found. The good value is 'Neukloster Straße'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the correctness of the hyphenation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The check is to see if some names are composed by only two words or not composed by a name of a person.\n",
    "\n",
    "For clarity, only the first 10 name are exported but the whole list was inspected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T10:12:06.378520Z",
     "start_time": "2018-09-26T10:12:06.338775Z"
    }
   },
   "outputs": [],
   "source": [
    "names[names.value.str.match('\\w+\\-')][0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All are named from People and are composed by several words. It is all correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the correctness of the name composed by a place"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The name of the place are in general ended by 'er'. The name should be like 'Buxtehuder Straße'. All name composed by *erstraße, *erweg or *erplatz are suspect and should be verified.\n",
    "\n",
    "For clarity, only the first 10 name are exported but the whole list was inspected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T10:12:06.430189Z",
     "start_time": "2018-09-26T10:12:06.382069Z"
    }
   },
   "outputs": [],
   "source": [
    "names[names.value.str.match('.*er .*$')][0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find again the 'Neukloster Str.' but the rest seems to be correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about the one words names?\n",
    "\n",
    "For clarity, only the first 10 name are exported but the whole list was inspected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T10:12:06.478314Z",
     "start_time": "2018-09-26T10:12:06.431934Z"
    }
   },
   "outputs": [],
   "source": [
    "names[names.value.str.match('.*er(?:str|weg|platz).*$')][0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first look, it seems to be correct. Nevertheless a deeper inspection is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correction of values in the database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One error was found. 'Neukloster Straße' is named 'Neukloster Str.'. Let fixt it. We will do it in a programatical way. The process can be reused on other dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we can extract the name of the streets we want to change (this can be given by an algorithm which check the error with a dictionary)\n",
    "\n",
    "Let find a methode to correct all Str. abbreviations automaticaly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to correct such values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T10:12:06.545091Z",
     "start_time": "2018-09-26T10:12:06.480124Z"
    }
   },
   "outputs": [],
   "source": [
    "originalNames = names[names.value.str.match('.* ?[sS]tr\\.?$')]\n",
    "originalNames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can write a function which correct the name. As we see in german the words can be glued together or separated by a space or an hypen. Our methode must cover all those cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T10:12:06.580668Z",
     "start_time": "2018-09-26T10:12:06.546986Z"
    }
   },
   "outputs": [],
   "source": [
    "def ExpandAbbreviation(name):\n",
    "    pattern = '^(.*[ -]??)[sS]tr\\.?$'\n",
    "    s = re.match(pattern, name) \n",
    "    if s:\n",
    "        if s.group(1)[-1] in [' ', '-']:\n",
    "            return s.group(1) + 'Straße'\n",
    "        else:\n",
    "            return s.group(1) + 'straße'\n",
    "    else:\n",
    "        return name\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let tests some cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T10:12:06.601172Z",
     "start_time": "2018-09-26T10:12:06.584034Z"
    }
   },
   "outputs": [],
   "source": [
    "testNames = ['Test', 'Teststraße', 'Test Straße',\n",
    "             'Test Str.', 'Test Str',\n",
    "             'Test str.', 'Test str',\n",
    "             'Teststr.', 'Teststr',\n",
    "             'Test-foo-Str.', 'Test-foo-str'\n",
    "            ]\n",
    "for n in testNames:\n",
    "    print('{}\\t-->\\t{}'.format(n, ExpandAbbreviation(n)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works on the test cases. Let apply the functions on our values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T10:12:06.632278Z",
     "start_time": "2018-09-26T10:12:06.602697Z"
    }
   },
   "outputs": [],
   "source": [
    "newNames = originalNames['value'].apply(ExpandAbbreviation).values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T10:12:06.660629Z",
     "start_time": "2018-09-26T10:12:06.636511Z"
    }
   },
   "outputs": [],
   "source": [
    "newNames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The names are corrected. We have to correct them in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T10:12:06.694101Z",
     "start_time": "2018-09-26T10:12:06.664899Z"
    }
   },
   "outputs": [],
   "source": [
    "sqlUpdateRequest = 'UPDATE ways_tags SET value = \\'{}\\' WHERE value = \\'{}\\';'\n",
    "for i in range(len(originalNames['value'].values.flatten())):\n",
    "    sqlQuery = sqlUpdateRequest.format(newNames[i], originalNames['value'].values.flatten()[i])\n",
    "    c.execute(sqlQuery)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are the errors corrected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T10:12:06.784899Z",
     "start_time": "2018-09-26T10:12:06.697641Z"
    }
   },
   "outputs": [],
   "source": [
    "sqlQuery = 'SELECT DISTINCT value FROM ways_tags WHERE type == \\'addr\\' AND key=\\'street\\''\n",
    "names = pd.read_sql(sqlQuery, conn)\n",
    "names[names.value.str.match('.* ?[sS]tr\\.?$')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No more wrong value anymore but are they really corrected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T10:12:06.800433Z",
     "start_time": "2018-09-26T10:12:06.788209Z"
    }
   },
   "outputs": [],
   "source": [
    "names[names.value.str.match('Neukloster.*$')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All is fine now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check of the postcode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The postcodes in Germany are in a 5 Digit format. In the extracted area they should all in the form of by 21XXX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T17:28:11.937897Z",
     "start_time": "2018-09-26T17:28:11.915978Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>21644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>21129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>21647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>21643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    value\n",
       "0   21149\n",
       "1   21147\n",
       "2   21079\n",
       "3   21614\n",
       "4   21629\n",
       "5   21224\n",
       "6   21641\n",
       "7   21077\n",
       "8   21075\n",
       "9   21640\n",
       "10  21644\n",
       "11  21129\n",
       "12  21647\n",
       "13  21643"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlQuery = 'SELECT DISTINCT value FROM ways_tags WHERE type == \\'addr\\' AND key=\\'postcode\\''\n",
    "postcodes = pd.read_sql(sqlQuery, conn)\n",
    "postcodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All is correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list of postcode is not so long but it is easy to automated the check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T17:28:22.332877Z",
     "start_time": "2018-09-26T17:28:22.324629Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [value]\n",
       "Index: []"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postcodes[postcodes.value.str.match('(?!^21\\d{3}$)')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No bad postcode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check of the phone number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The german telephone numbers have a variable number of digits. They should begin with +49."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T17:37:48.967841Z",
     "start_time": "2018-09-26T17:37:48.948078Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>+49 40 79686761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>+49 40 7020700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>+49 4161 727 160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>+49 4161 554354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>+49 4161 727162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>+49 4161 511410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>04161 7439-70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>+49 4161 743950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>+49 4161 7433 60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>+49 4161 7424 0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              value\n",
       "0   +49 40 79686761\n",
       "1    +49 40 7020700\n",
       "2  +49 4161 727 160\n",
       "3   +49 4161 554354\n",
       "4   +49 4161 727162\n",
       "5   +49 4161 511410\n",
       "6     04161 7439-70\n",
       "7   +49 4161 743950\n",
       "8  +49 4161 7433 60\n",
       "9   +49 4161 7424 0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlQuery = 'SELECT DISTINCT value FROM ways_tags WHERE type == \\'contact\\' AND key=\\'phone\\''\n",
    "phoneNumbers = pd.read_sql(sqlQuery, conn)\n",
    "phoneNumbers[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T18:00:14.222794Z",
     "start_time": "2018-09-26T18:00:14.215625Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>04161 7439-70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>+49 4161 6447-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>+49 4161 7160-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>04161 7439-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>040 7026655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>04161 72540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>04161 645637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>04161 7260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>04161 84850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>+49 40 570063-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>+49 4161 727141 +49 4161 727272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>+49 4108 59067-0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              value\n",
       "6                     04161 7439-70\n",
       "16                 +49 4161 6447-15\n",
       "24                  +49 4161 7160-0\n",
       "25                    04161 7439-30\n",
       "33                      040 7026655\n",
       "35                      04161 72540\n",
       "42                     04161 645637\n",
       "44                       04161 7260\n",
       "46                      04161 84850\n",
       "56                  +49 40 570063-0\n",
       "85  +49 4161 727141 +49 4161 727272\n",
       "86                 +49 4108 59067-0"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "badPhoneNumbers = phoneNumbers[phoneNumbers.value.str.match('(?!^\\+49[0-9 ]+$)')]\n",
    "badPhoneNumbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have some number without +49 some numbers with some hypen and a double one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for the street we can write a function to correct the phone numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T17:55:57.288652Z",
     "start_time": "2018-09-26T17:55:57.283811Z"
    }
   },
   "outputs": [],
   "source": [
    "def correctPhoneNumbers(number):\n",
    "    # Supress the hyphen\n",
    "    correctedNumber = number.replace('-', ' ')\n",
    "    \n",
    "    # Add a proper +49 at the beginning of the number\n",
    "    if correctedNumber[0] == '0':\n",
    "        correctedNumber = '+49 ' + correctedNumber[1:]\n",
    "    \n",
    "    # If several number are present take only the first\n",
    "    pattern = '^(\\+49[0-9 ]+).*$'\n",
    "    res = re.match(pattern, correctedNumber)\n",
    "    if res:\n",
    "        correctedNumber = res.group(1).rstrip()\n",
    "        \n",
    "    return (number, correctedNumber)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let tests some cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T17:56:48.603073Z",
     "start_time": "2018-09-26T17:56:48.599434Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+49 123-456\t-->\t+49 123 456\n",
      "04 555 111\t-->\t+49 4 555 111\n",
      "+49 123 456 +49 789 0123\t-->\t+49 123 456\n"
     ]
    }
   ],
   "source": [
    "TestNumbers = ['+49 123-456', '04 555 111', '+49 123 456 +49 789 0123']\n",
    "for n in TestNumbers:\n",
    "    correctedNumber = correctPhoneNumbers(n)\n",
    "    print('{}\\t-->\\t{}'.format(correctedNumber[0], correctedNumber[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T18:01:58.964234Z",
     "start_time": "2018-09-26T18:01:58.960121Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([('04161 7439-70', '+49 4161 7439 70'),\n",
       "       ('+49 4161 6447-15', '+49 4161 6447 15'),\n",
       "       ('+49 4161 7160-0', '+49 4161 7160 0'),\n",
       "       ('04161 7439-30', '+49 4161 7439 30'),\n",
       "       ('040 7026655', '+49 40 7026655'),\n",
       "       ('04161 72540', '+49 4161 72540'),\n",
       "       ('04161 645637', '+49 4161 645637'),\n",
       "       ('04161 7260', '+49 4161 7260'), ('04161 84850', '+49 4161 84850'),\n",
       "       ('+49 40 570063-0', '+49 40 570063 0'),\n",
       "       ('+49 4161 727141 +49 4161 727272', '+49 4161 727141'),\n",
       "       ('+49 4108 59067-0', '+49 4108 59067 0')], dtype=object)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phoneNumberCorrection = badPhoneNumbers['value'].apply(correctPhoneNumbers).values\n",
    "phoneNumberCorrection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The names are corrected. We have to correct them in the database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T18:05:00.840557Z",
     "start_time": "2018-09-26T18:05:00.838116Z"
    }
   },
   "source": [
    "### Correction of the phone numbers in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T18:10:05.219755Z",
     "start_time": "2018-09-26T18:10:05.083546Z"
    }
   },
   "outputs": [],
   "source": [
    "sqlUpdateRequest = 'UPDATE ways_tags SET value = \\'{}\\' WHERE value = \\'{}\\';'\n",
    "for nb in phoneNumberCorrection:\n",
    "    sqlQuery = sqlUpdateRequest.format(nb[1], nb[0])\n",
    "    c.execute(sqlQuery)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are the errors corrected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T18:09:42.872057Z",
     "start_time": "2018-09-26T18:09:42.852544Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [value]\n",
       "Index: []"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlQuery = 'SELECT DISTINCT value FROM ways_tags WHERE type == \\'contact\\' AND key=\\'phone\\''\n",
    "phoneNumbers = pd.read_sql(sqlQuery, conn)\n",
    "badPhoneNumbers = phoneNumbers[phoneNumbers.value.str.match('(?!^\\+49[0-9 ]+$)')]\n",
    "badPhoneNumbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No more wrong value anymore but are they really corrected?\n",
    "\n",
    "There are not a lot of error. A complete check is possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T18:14:19.275946Z",
     "start_time": "2018-09-26T18:14:19.264248Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['+49 4161 7439 70']]\n",
      "[['+49 4161 6447 15']]\n",
      "[['+49 4161 7160 0']]\n",
      "[['+49 4161 7439 30']]\n",
      "[['+49 40 7026655']]\n",
      "[['+49 4161 72540']]\n",
      "[['+49 4161 645637']]\n",
      "[['+49 4161 7260']]\n",
      "[['+49 4161 84850']]\n",
      "[['+49 40 570063 0']]\n",
      "[['+49 4161 727141']]\n",
      "[['+49 4108 59067 0']]\n"
     ]
    }
   ],
   "source": [
    "for nb in phoneNumberCorrection:\n",
    "    print(phoneNumbers[phoneNumbers['value'] == nb[1]].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the phone number are corrected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check of the fax numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same methode can be applied for the fax numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T18:18:10.957042Z",
     "start_time": "2018-09-26T18:18:10.936527Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>04161 7439-75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>+49 4161 6447-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>+49 4161 7160-42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>04161 7439-35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>04161 85322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>04161 645638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>04161 726299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>04161 78551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>+49 40 570063-499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>+49 4108 59067-29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                value\n",
       "1       04161 7439-75\n",
       "9    +49 4161 6447-10\n",
       "16   +49 4161 7160-42\n",
       "17      04161 7439-35\n",
       "23        04161 85322\n",
       "29       04161 645638\n",
       "30       04161 726299\n",
       "32        04161 78551\n",
       "40  +49 40 570063-499\n",
       "55  +49 4108 59067-29"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlQuery = 'SELECT DISTINCT value FROM ways_tags WHERE type == \\'contact\\' AND key=\\'fax\\''\n",
    "faxNumbers = pd.read_sql(sqlQuery, conn)\n",
    "badFaxNumbers = faxNumbers[faxNumbers.value.str.match('(?!^\\+49[0-9 ]+$)')]\n",
    "badFaxNumbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T18:18:56.194850Z",
     "start_time": "2018-09-26T18:18:56.190911Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([('04161 7439-75', '+49 4161 7439 75'),\n",
       "       ('+49 4161 6447-10', '+49 4161 6447 10'),\n",
       "       ('+49 4161 7160-42', '+49 4161 7160 42'),\n",
       "       ('04161 7439-35', '+49 4161 7439 35'),\n",
       "       ('04161 85322', '+49 4161 85322'),\n",
       "       ('04161 645638', '+49 4161 645638'),\n",
       "       ('04161 726299', '+49 4161 726299'),\n",
       "       ('04161 78551', '+49 4161 78551'),\n",
       "       ('+49 40 570063-499', '+49 40 570063 499'),\n",
       "       ('+49 4108 59067-29', '+49 4108 59067 29')], dtype=object)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faxNumberCorrection = badFaxNumbers['value'].apply(correctPhoneNumbers).values\n",
    "faxNumberCorrection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correction of the bad fax number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T18:20:08.855961Z",
     "start_time": "2018-09-26T18:20:08.740318Z"
    }
   },
   "outputs": [],
   "source": [
    "sqlUpdateRequest = 'UPDATE ways_tags SET value = \\'{}\\' WHERE value = \\'{}\\';'\n",
    "for nb in faxNumberCorrection:\n",
    "    sqlQuery = sqlUpdateRequest.format(nb[1], nb[0])\n",
    "    c.execute(sqlQuery)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are the errors corrected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T18:21:20.256332Z",
     "start_time": "2018-09-26T18:21:20.237275Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [value]\n",
       "Index: []"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlQuery = 'SELECT DISTINCT value FROM ways_tags WHERE type == \\'contact\\' AND key=\\'fax\\''\n",
    "faxNumbers = pd.read_sql(sqlQuery, conn)\n",
    "faxNumbers[faxNumbers.value.str.match('(?!^\\+49[0-9 ]+$)')]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No more wrong value anymore but are they really corrected?\n",
    "\n",
    "There are not a lot of error. A complete check is possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T18:21:38.183677Z",
     "start_time": "2018-09-26T18:21:38.174347Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['+49 4161 7439 75']]\n",
      "[['+49 4161 6447 10']]\n",
      "[['+49 4161 7160 42']]\n",
      "[['+49 4161 7439 35']]\n",
      "[['+49 4161 85322']]\n",
      "[['+49 4161 645638']]\n",
      "[['+49 4161 726299']]\n",
      "[['+49 4161 78551']]\n",
      "[['+49 40 570063 499']]\n",
      "[['+49 4108 59067 29']]\n"
     ]
    }
   ],
   "source": [
    "for nb in faxNumberCorrection:\n",
    "    print(faxNumbers[faxNumbers['value'] == nb[1]].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All fax numbers are corrected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many nodes in the database?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T10:12:04.395909Z",
     "start_time": "2018-09-26T10:12:04.375735Z"
    }
   },
   "outputs": [],
   "source": [
    "c.execute('SELECT COUNT(id) FROM nodes')\n",
    "print('There are {} nodes in the database'.format(c.fetchall()[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many ways in the database?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T10:12:04.451754Z",
     "start_time": "2018-09-26T10:12:04.397469Z"
    }
   },
   "outputs": [],
   "source": [
    "c.execute('SELECT COUNT(id) FROM ways')\n",
    "print('There are {} ways in the database'.format(c.fetchall()[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many users are in the tables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T10:12:04.587675Z",
     "start_time": "2018-09-26T10:12:04.453197Z"
    }
   },
   "outputs": [],
   "source": [
    "c.execute('SELECT COUNT(DISTINCT user) FROM ways')\n",
    "print('There are {} different users in the ways table'.format(c.fetchall()[0][0]))\n",
    "\n",
    "c.execute('SELECT COUNT(DISTINCT user) FROM nodes')\n",
    "print('There are {} different users in the nodes table'.format(c.fetchall()[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of different type of elements in the file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to have an idea of what sort of information are contains by having a look to the field 'type' of the nodes tags.\n",
    "\n",
    "For clarity, only a part of the type are displayed here. Replace the last line by 'print(df.values)' to see the whole list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T10:12:04.684891Z",
     "start_time": "2018-09-26T10:12:04.592451Z"
    }
   },
   "outputs": [],
   "source": [
    "sqlQuery = 'SELECT DISTINCT nodes_tags.type \\\n",
    "          FROM nodes_tags;'\n",
    "df = pd.read_sql(sqlQuery, conn)\n",
    "print(df.values[20:35])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What about fire protection?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The type 'water_hydrant' can be interessing to see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T10:12:04.722230Z",
     "start_time": "2018-09-26T10:12:04.686538Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "c.execute('SELECT count(type) \\\n",
    "          FROM nodes_tags \\\n",
    "          WHERE type == \\'fire_hydrant\\' AND nodes_tags.key = \\'type\\';')\n",
    "print('There are {} fire hydrants in the database'.format(c.fetchall()[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should be possible to see their location. We can extract their position in latitude and longitude from the nodes table.\n",
    "\n",
    "Displaying only the position it is hard to really see. We will extract also the ways and the name of the places.\n",
    "\n",
    "*Note: For performance reason, the map can take some times to be generated. It is possible to activate the generation of the ways by setting the parameter 'plotWays' to True. The parameter 'plotPlace' can also be set to False but it not improve the performance just the visualisation.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T10:12:04.878091Z",
     "start_time": "2018-09-26T10:12:04.723790Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Function to plot the ways and the name of the place\n",
    "\n",
    "def plotMap(plotWays = False, plotPlaces = True):\n",
    "    # Extraction of the ways.\n",
    "    if plotWays:\n",
    "        sqlQuery = 'SELECT ways_nodes.id, ways_nodes.position, nodes.lat, nodes.lon \\\n",
    "              FROM ways_nodes \\\n",
    "              JOIN nodes \\\n",
    "              WHERE ways_nodes.node_id = nodes.id;'\n",
    "        df = pd.read_sql(sqlQuery, conn)\n",
    "        wayList = df['id'].unique()\n",
    "        for way in wayList:\n",
    "            singleWay = df[df['id'] == way].sort_values(by = ['position'])\n",
    "            plt.plot(singleWay['lon'], singleWay['lat'], c='k', alpha=0.3)\n",
    "    \n",
    "    # Extraction of the name of the place.\n",
    "    # For that a self join is needed because the name of the place separate from the type.\n",
    "    # Also in name are given in German and Plattdeutsch. Only the German name should be selected\n",
    "    # (it is the reason of the 'B.key IS NULL')\n",
    "    if plotPlaces:\n",
    "        sqlQuery = 'SELECT B.value, nodes.lat, nodes.lon \\\n",
    "              FROM nodes_tags A, nodes_tags B \\\n",
    "              JOIN nodes \\\n",
    "              ON nodes.id = A.id \\\n",
    "              WHERE A.type = \\'place\\' \\\n",
    "              AND B.type = \\'name\\' AND B.key IS NULL\\\n",
    "              AND A.id = B.id;'\n",
    "        df = pd.read_sql(sqlQuery, conn)\n",
    "        for i in range(df.shape[0]):\n",
    "            plt.annotate(df.iloc[i]['value'], xy=(df.iloc[i]['lon'], df.iloc[i]['lat']), fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T10:12:06.292912Z",
     "start_time": "2018-09-26T10:12:04.879653Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Extract all Fire_hydrant with their latitude and longitude\n",
    "sqlQuery = 'SELECT nodes.lat, nodes.lon, nodes_tags.type, nodes_tags.key, nodes_tags.value \\\n",
    "          FROM nodes \\\n",
    "          JOIN nodes_tags ON nodes.id = nodes_tags.id \\\n",
    "          WHERE nodes_tags.type == \\'fire_hydrant\\' AND nodes_tags.key = \\'type\\';'\n",
    "df = pd.read_sql(sqlQuery, conn)\n",
    "\n",
    "\n",
    "plt.figure(num=None, figsize=(20, 15), dpi=80, facecolor='w', edgecolor='k')  \n",
    "plotMap(plotWays = False)\n",
    "plt.title('Position of fire hydrants', fontdict={'fontsize': 30})\n",
    "plt.xlabel('Longitude', fontdict={'fontsize': 20})\n",
    "plt.ylabel('Latitude', fontdict={'fontsize': 20})\n",
    "plt.scatter(df['lon'], df['lat'], marker='x', s=70, c='r', alpha=0.9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some empty areas are clearly visible in the land part. This probably due to a lack of information. The land part are less covered by people who update the map. To improve the map, some effort can be done for the village without information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Close the database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the database connection can be closed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T10:12:06.849915Z",
     "start_time": "2018-09-26T10:12:06.801783Z"
    }
   },
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Possible improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use a dictionary\n",
    "\n",
    "As we see the naming convention is quite tricky. To check a dataset manually it can be a long boring job. Reduce the workload. A diationary approch can be used to remove the name which are clearly legal. The manual work will be reduce to the suspect names.\n",
    "\n",
    "This can be done for the name based on people name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross the data on a bigger dataset\n",
    "\n",
    "Another approch to find suspicious name is to cross the data with a biger dataset. The name of the place and street are very often redundant to a city to another. It is possible to extract the root of the names and compare the difference between the places.\n",
    "\n",
    "If we concidere that the database contains data of good quality, we can supose that in average the name are good. A statiscal approch is probably a good one. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Better visualisation\n",
    "\n",
    "We saw that the data are probably missing. A better visualisation (not only the fire hydrants) can be used to see were to look to improve the coverage of the map."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "281.767px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
